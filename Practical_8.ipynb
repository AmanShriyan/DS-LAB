{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwIwzBuy4MgT"
      },
      "source": [
        "<center>\n",
        "    <h1>Natural Language Processing</h1>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZYpt0IFL4MgX",
        "outputId": "fb831af3-06af-4de0-97ad-907172235c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HelloGoodMorninghiiiii'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Data cleaning\n",
        "\n",
        "punct=\"'!@$%^&*#><?.-_,{}()[]\"\n",
        "my_str=\"Hello!!!!...Good_-Morning(hiiiii...)\"\n",
        "no_punct=\"\"\n",
        "for char in my_str:\n",
        "  if(char not in punct):\n",
        "    no_punct=no_punct + char \n",
        "no_punct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0nHwcRG4MgZ",
        "outputId": "009eaccb-6297-4874-d5d4-d22fe802d560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['The', 'quick', 'brown', 'is', 'an', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "\n",
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "#function to split text into word\n",
        "tokens=word_tokenize(\"The quick brown is an fox jumps over the lazy dog\")\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEQnU1KJ4Mga",
        "outputId": "12c85f7c-ecb4-4240-fa19-5f16b524c6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['The', 'quick', 'brown', 'is', 'an', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
            "['The', 'quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n"
          ]
        }
      ],
      "source": [
        "# Removing stop words\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words('english')\n",
        "print(tokens)\n",
        "# print(stop_words)\n",
        " \n",
        "#removing stopwords\n",
        "tokens = [w for w in tokens if not w in stop_words]\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFVdawW4Mga",
        "outputId": "a1926bb1-11ca-4c32-9d48-435f4f84420f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there\n",
            "are\n",
            "the\n",
            "sever\n",
            "type\n",
            "of\n",
            "stem\n",
            "algorithm\n"
          ]
        }
      ],
      "source": [
        "# Stemming\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "input_str=\"There are the several types of stemming algorithm\"\n",
        "input_str=nltk.word_tokenize(input_str)\n",
        "for word in input_str:    \n",
        "    print(stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuYqJi-V4Mgb",
        "outputId": "6fb641f5-428f-43de-f669-ea90460c7483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
            "been\n",
            "had\n",
            "done\n",
            "a\n",
            "language\n",
            "city\n",
            "mouse\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization \n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "input_str=\"been had done a languages cities mice\"\n",
        "input_str=nltk.word_tokenize(input_str)\n",
        "for word in input_str:    \n",
        "    print(lemmatizer.lemmatize(word))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP5Z3rn14Mgb",
        "outputId": "adaafacd-f480-4717-80cc-366fbb7b05ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Albert', 'NNP'),\n",
              " ('Einstein', 'NNP'),\n",
              " ('was', 'VBD'),\n",
              " ('born', 'VBN'),\n",
              " ('in', 'IN'),\n",
              " ('Ulm', 'NNP'),\n",
              " (',', ','),\n",
              " ('Germany', 'NNP'),\n",
              " ('in', 'IN'),\n",
              " ('1879', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# POS Tagging\n",
        "\n",
        "sent = \"Albert Einstein was born in Ulm, Germany in 1879.\"\n",
        "tokens=nltk.word_tokenize(sent)\n",
        "# print(tokens)\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXhUCB2q4Mgc"
      },
      "source": [
        "<center>\n",
        "    <h1>Creating TF-IDF Model</h1>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diHtWBf_4Mgc"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD8BElWl4Mgd"
      },
      "outputs": [],
      "source": [
        "first_sentence = \"John is a very good singer\"\n",
        "second_sentence = \"Bob is the friend of John who likes to play guitar\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewq95LRV4Mgd",
        "outputId": "174a8b55-cf7e-4f9e-bfb7-a98c823d842d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Bob', 'of', 'play', 'John', 'good', 'the', 'who', 'a', 'very', 'singer', 'friend', 'to', 'guitar', 'likes', 'is'}\n"
          ]
        }
      ],
      "source": [
        "#split so each word have their own string\n",
        "\n",
        "first = first_sentence.split(\" \")\n",
        "second = second_sentence.split(\" \")\n",
        "\n",
        "#join them to remove common duplicate words\n",
        "total= set(first).union(set(second))\n",
        "print(total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfODzqL64Mge"
      },
      "outputs": [],
      "source": [
        "# count the words using a dictionary \n",
        "\n",
        "wordDictA = dict.fromkeys(total, 0)\n",
        "wordDictB = dict.fromkeys(total, 0)\n",
        "for word in first:\n",
        "   wordDictA[word]+=1\n",
        "  \n",
        "for word in second:\n",
        "   wordDictB[word]+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9k89pOj4Mge",
        "outputId": "59d4df7a-3127-4874-cd3d-6f92d201d25a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bob</th>\n",
              "      <th>of</th>\n",
              "      <th>play</th>\n",
              "      <th>John</th>\n",
              "      <th>good</th>\n",
              "      <th>the</th>\n",
              "      <th>who</th>\n",
              "      <th>a</th>\n",
              "      <th>very</th>\n",
              "      <th>singer</th>\n",
              "      <th>friend</th>\n",
              "      <th>to</th>\n",
              "      <th>guitar</th>\n",
              "      <th>likes</th>\n",
              "      <th>is</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Bob  of  play  John  good  the  who  a  very  singer  friend  to  guitar  \\\n",
              "0    0   0     0     1     1    0    0  1     1       1       0   0       0   \n",
              "1    1   1     1     1     0    1    1  0     0       0       1   1       1   \n",
              "\n",
              "   likes  is  \n",
              "0      0   1  \n",
              "1      1   1  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# put them in a dataframe\n",
        "\n",
        "pd.DataFrame([wordDictA, wordDictB])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7RfC_Fy4Mge",
        "outputId": "4d0042c1-8df3-4873-957e-db5788605ca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bob</th>\n",
              "      <th>of</th>\n",
              "      <th>play</th>\n",
              "      <th>John</th>\n",
              "      <th>good</th>\n",
              "      <th>the</th>\n",
              "      <th>who</th>\n",
              "      <th>a</th>\n",
              "      <th>very</th>\n",
              "      <th>singer</th>\n",
              "      <th>friend</th>\n",
              "      <th>to</th>\n",
              "      <th>guitar</th>\n",
              "      <th>likes</th>\n",
              "      <th>is</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Bob        of      play      John      good       the       who  \\\n",
              "0  0.000000  0.000000  0.000000  0.166667  0.166667  0.000000  0.000000   \n",
              "1  0.090909  0.090909  0.090909  0.090909  0.000000  0.090909  0.090909   \n",
              "\n",
              "          a      very    singer    friend        to    guitar     likes  \\\n",
              "0  0.166667  0.166667  0.166667  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.000000  0.000000  0.000000  0.090909  0.090909  0.090909  0.090909   \n",
              "\n",
              "         is  \n",
              "0  0.166667  \n",
              "1  0.090909  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TF Function :\n",
        "\n",
        "def computeTF(wordDict, doc):\n",
        "   tfDict = {}\n",
        "   corpusCount = len(doc)\n",
        "   for word, count in wordDict.items():\n",
        "       tfDict[word] = count/float(corpusCount)\n",
        "   return(tfDict)\n",
        "\n",
        "\n",
        "# Calling tf function:\n",
        "tfFirst = computeTF(wordDictA, first)\n",
        "tfSecond = computeTF(wordDictB, second)\n",
        "\n",
        "\n",
        "#Converting to dataframe for visualization\n",
        "tf = pd.DataFrame([tfFirst, tfSecond])\n",
        "\n",
        "\n",
        "tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k1_zX254Mgf",
        "outputId": "c2acff87-733d-4f1f-fe85-98bc669ec980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bob', 'play', 'John', 'good', 'singer', 'friend', 'guitar', 'likes']\n"
          ]
        }
      ],
      "source": [
        "# Removing Stop words\n",
        "\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_sentence = [w for w in wordDictA if not w in stop_words]\n",
        "print(filtered_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NjBO3Ee4Mgf",
        "outputId": "78f1f8b8-39c7-4049-ab49-38240e87e2bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Bob': 0.3010299956639812,\n",
              " 'of': 0.3010299956639812,\n",
              " 'play': 0.3010299956639812,\n",
              " 'John': 0.3010299956639812,\n",
              " 'good': 0.3010299956639812,\n",
              " 'the': 0.3010299956639812,\n",
              " 'who': 0.3010299956639812,\n",
              " 'a': 0.3010299956639812,\n",
              " 'very': 0.3010299956639812,\n",
              " 'singer': 0.3010299956639812,\n",
              " 'friend': 0.3010299956639812,\n",
              " 'to': 0.3010299956639812,\n",
              " 'guitar': 0.3010299956639812,\n",
              " 'likes': 0.3010299956639812,\n",
              " 'is': 0.3010299956639812}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate IDF\n",
        "\n",
        "def computeIDF(docList):\n",
        "   idfDict = {}\n",
        "   N = len(docList)\n",
        "  \n",
        "   idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "   for word, val in idfDict.items():\n",
        "       idfDict[word] = math.log10(N / (float(val) + 1))\n",
        "      \n",
        "   return(idfDict)\n",
        "#inputing our sentences in the log file\n",
        "idfs = computeIDF([wordDictA, wordDictB])\n",
        "\n",
        "idfs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmdhgWnV4Mgf",
        "outputId": "dba205af-3f0a-409c-b7c7-5517993b92df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bob</th>\n",
              "      <th>of</th>\n",
              "      <th>play</th>\n",
              "      <th>John</th>\n",
              "      <th>good</th>\n",
              "      <th>the</th>\n",
              "      <th>who</th>\n",
              "      <th>a</th>\n",
              "      <th>very</th>\n",
              "      <th>singer</th>\n",
              "      <th>friend</th>\n",
              "      <th>to</th>\n",
              "      <th>guitar</th>\n",
              "      <th>likes</th>\n",
              "      <th>is</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.050172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "      <td>0.027366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Bob        of      play      John      good       the       who  \\\n",
              "0  0.000000  0.000000  0.000000  0.050172  0.050172  0.000000  0.000000   \n",
              "1  0.027366  0.027366  0.027366  0.027366  0.000000  0.027366  0.027366   \n",
              "\n",
              "          a      very    singer    friend        to    guitar     likes  \\\n",
              "0  0.050172  0.050172  0.050172  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.000000  0.000000  0.000000  0.027366  0.027366  0.027366  0.027366   \n",
              "\n",
              "         is  \n",
              "0  0.050172  \n",
              "1  0.027366  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate TF-IDF\n",
        "\n",
        "def computeTFIDF(tfBow, idfs):\n",
        "   tfidf = {}\n",
        "   for word, val in tfBow.items():\n",
        "       tfidf[word] = val*idfs[word]\n",
        "   return(tfidf)\n",
        "\n",
        "#running our two sentences through the IDF:\n",
        "idfFirst = computeTFIDF(tfFirst, idfs)\n",
        "idfSecond = computeTFIDF(tfSecond, idfs)\n",
        "\n",
        "\n",
        "#putting it in a dataframe\n",
        "tfidf= pd.DataFrame([idfFirst, idfSecond])\n",
        "tfidf\n",
        "# print(tfidf)\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f507979fbbadbb87ffb64bd5a5dedefe97bceb4da6a0848a7923fb69079d45ee"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Practical_8.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}